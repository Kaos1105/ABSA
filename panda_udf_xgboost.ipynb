{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f332e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.5.1 in ./.conda/lib/python3.11/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.conda/lib/python3.11/site-packages (from pyspark==3.5.1) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: findspark in ./.conda/lib/python3.11/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: joblib in ./.conda/lib/python3.11/site-packages (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in ./.conda/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in ./.conda/lib/python3.11/site-packages (3.0.5)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (from xgboost) (2.3.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./.conda/lib/python3.11/site-packages (from xgboost) (2.28.3)\n",
      "Requirement already satisfied: scipy in ./.conda/lib/python3.11/site-packages (from xgboost) (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-21.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark==3.5.1\n",
    "%pip install pandas\n",
    "%pip install findspark\n",
    "%pip install joblib\n",
    "%pip install scikit-learn\n",
    "%pip install xgboost\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7625c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# PATH definitions\n",
    "DATA_DIR = \"./dataset\"  # ƒë·ªïi n·∫øu d√πng Drive\n",
    "MODEL_DIR = \"./models\"\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train_data.csv\")\n",
    "VAL_PATH   = os.path.join(DATA_DIR, \"val_data.csv\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16759867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "TEXT_COL = \"Review\"\n",
    "ASPECTS  = [\"Price\",\"Shipping\",\"Outlook\",\"Quality\",\"Size\",\"Shop_Service\",\"General\",\"Others\"]\n",
    "\n",
    "# Label mapping\n",
    "SENT_ID2NAME = {-1: \"None\", 0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
    "LABEL_VALUES = list(SENT_ID2NAME.keys())  # [-1, 0, 1, 2]\n",
    "LABEL_NAMES  = list(SENT_ID2NAME.values())  # [\"None\",\"Negative\",\"Positive\",\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17faa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities function \n",
    "import re, unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "MULTISPACE_RE = re.compile(r\"\\s+\")\n",
    "VIETNAMESE_BASIC_STOPWORDS = set(\"\"\"\n",
    "v√† ho·∫∑c nh∆∞ng l√† th√¨ m√† ƒë∆∞·ª£c b·ªã c·ªßa cho v·ªõi v·ªÅ t·ª´ t·ªõi ƒë·∫øn n·ªói do v√¨ n√™n n·∫øu khi ƒë·ªÉ b·∫±ng nh∆∞ l·∫°i ƒë√£ ƒëang s·∫Ω kh√¥ng ch∆∞a ch·∫≥ng r·∫•t qu√° l·∫Øm h∆°i\n",
    "n√†y kia n·ªç ƒë√≥ ƒë√¢y ·∫•y v·∫≠y th·∫ø sao t·∫°i v√¨ do ƒë√≥ tuy nhi√™n h∆°n k√©m ch·ªâ m·ªói m·ªôt c√°c nh·ªØng c√°i con chi·∫øc ƒë√¥i ƒëc nh√© nha ·∫° ∆°i\n",
    "\"\"\".split())\n",
    "\n",
    "def preprocess_xgb(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.strip().lower()\n",
    "    text = URL_RE.sub(\" \", text)\n",
    "    text = TAG_RE.sub(\" \", text)\n",
    "    text = text.replace(\"‚ù§Ô∏è\", \" yeu \").replace(\"‚ù§\", \" yeu \").replace(\"üòç\", \" yeu \")\n",
    "    text = re.sub(r\"[^\\w\\s√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]\", \" \", text)\n",
    "    text = unicodedata.normalize(\"NFC\", text)  # normalize accents\n",
    "    text = MULTISPACE_RE.sub(\" \", text).strip()\n",
    "    tokens = [w for w in text.split() if w not in VIETNAMESE_BASIC_STOPWORDS]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0248158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge(train_path, val_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df   = pd.read_csv(val_path)\n",
    "    test_df  = pd.read_csv(test_path)\n",
    "\n",
    "    # Merge train + val\n",
    "    full_train = pd.concat([train_df, val_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Preprocess review text\n",
    "    full_train[TEXT_COL] = full_train[TEXT_COL].map(preprocess_xgb)\n",
    "    test_df[TEXT_COL]    = test_df[TEXT_COL].map(preprocess_xgb)\n",
    "\n",
    "    return full_train, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f762269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ==== STORAGE ====\n",
    "\n",
    "def train_xgb_models(train_df, test_df):\n",
    "    models = {}\n",
    "    encoders = {}\n",
    "    reports = {}\n",
    "\n",
    "    for aspect in ASPECTS:\n",
    "        print(f\"\\n=== Training aspect: {aspect} ===\")\n",
    "\n",
    "        # Encode labels\n",
    "        le = LabelEncoder()\n",
    "        y_train = le.fit_transform(train_df[aspect])\n",
    "        y_test  = le.transform(test_df[aspect])\n",
    "        encoders[aspect] = le\n",
    "\n",
    "        # Build pipeline: TF-IDF + XGBoost\n",
    "        pipe = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "            (\"xgb\", XGBClassifier(\n",
    "                n_estimators=300,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric=\"mlogloss\"\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        # Train\n",
    "        pipe.fit(train_df[TEXT_COL], y_train)\n",
    "        models[aspect] = pipe\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred_encoded = pipe.predict(test_df[TEXT_COL])\n",
    "        y_pred_original = le.inverse_transform(y_pred_encoded)\n",
    "        y_test_original = le.inverse_transform(y_test)\n",
    "\n",
    "        report = classification_report(y_test_original, y_pred_original, labels=LABEL_VALUES, target_names=LABEL_NAMES)\n",
    "        print(report)\n",
    "\n",
    "        models[aspect] = pipe\n",
    "        reports[aspect] = report\n",
    "\n",
    "    return models, encoders, reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ad9c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aspects(models, encoders, texts):\n",
    "    texts = [preprocess_xgb(t) for t in texts]\n",
    "    results = {}\n",
    "    for aspect, model in models.items():\n",
    "        pred_encoded = model.predict(texts)                # e.g. [0,1,2,3]\n",
    "        pred_original = encoders[aspect].inverse_transform(pred_encoded)  # e.g. [-1,0,1,2]\n",
    "        results[aspect] = [SENT_ID2NAME[int(x)] for x in pred_original]\n",
    "    return pd.DataFrame(results, index=range(len(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef49103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training aspect: Price ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:30:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.95      0.98      0.97      1999\n",
      "    Negative       0.00      0.00      0.00         3\n",
      "    Positive       0.91      0.82      0.86       247\n",
      "     Neutral       0.61      0.36      0.46        91\n",
      "\n",
      "    accuracy                           0.94      2340\n",
      "   macro avg       0.62      0.54      0.57      2340\n",
      "weighted avg       0.93      0.94      0.94      2340\n",
      "\n",
      "\n",
      "=== Training aspect: Shipping ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:31:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.98      0.98      0.98      1635\n",
      "    Negative       0.82      0.85      0.83       124\n",
      "    Positive       0.91      0.95      0.93       549\n",
      "     Neutral       0.25      0.06      0.10        32\n",
      "\n",
      "    accuracy                           0.95      2340\n",
      "   macro avg       0.74      0.71      0.71      2340\n",
      "weighted avg       0.94      0.95      0.95      2340\n",
      "\n",
      "\n",
      "=== Training aspect: Outlook ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:32:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.89      0.93      0.91      1069\n",
      "    Negative       0.67      0.46      0.55        95\n",
      "    Positive       0.91      0.93      0.92      1118\n",
      "     Neutral       0.27      0.05      0.09        58\n",
      "\n",
      "    accuracy                           0.89      2340\n",
      "   macro avg       0.68      0.59      0.62      2340\n",
      "weighted avg       0.87      0.89      0.88      2340\n",
      "\n",
      "\n",
      "=== Training aspect: Quality ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:33:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.91      0.95      0.93      1654\n",
      "    Negative       0.70      0.33      0.44        98\n",
      "    Positive       0.78      0.83      0.81       478\n",
      "     Neutral       0.49      0.22      0.30       110\n",
      "\n",
      "    accuracy                           0.87      2340\n",
      "   macro avg       0.72      0.58      0.62      2340\n",
      "weighted avg       0.85      0.87      0.86      2340\n",
      "\n",
      "\n",
      "=== Training aspect: Size ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:34:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.96      0.97      0.97      1953\n",
      "    Negative       0.60      0.62      0.61       125\n",
      "    Positive       0.74      0.77      0.76       165\n",
      "     Neutral       0.36      0.23      0.28        97\n",
      "\n",
      "    accuracy                           0.91      2340\n",
      "   macro avg       0.67      0.65      0.65      2340\n",
      "weighted avg       0.90      0.91      0.90      2340\n",
      "\n",
      "\n",
      "=== Training aspect: Shop_Service ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:35:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.92      0.97      0.95      1740\n",
      "    Negative       0.70      0.49      0.58       140\n",
      "    Positive       0.81      0.77      0.79       431\n",
      "     Neutral       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.89      2340\n",
      "   macro avg       0.61      0.56      0.58      2340\n",
      "weighted avg       0.88      0.89      0.89      2340\n",
      "\n",
      "\n",
      "=== Training aspect: General ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:36:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.88      0.96      0.92      1861\n",
      "    Negative       0.00      0.00      0.00        11\n",
      "    Positive       0.69      0.45      0.54       285\n",
      "     Neutral       0.58      0.36      0.44       183\n",
      "\n",
      "    accuracy                           0.85      2340\n",
      "   macro avg       0.54      0.44      0.48      2340\n",
      "weighted avg       0.83      0.85      0.83      2340\n",
      "\n",
      "\n",
      "=== Training aspect: Others ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [13:36:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        None       0.97      0.99      0.98      2151\n",
      "    Negative       0.00      0.00      0.00         0\n",
      "    Positive       0.00      0.00      0.00         0\n",
      "     Neutral       0.88      0.65      0.75       189\n",
      "\n",
      "    accuracy                           0.96      2340\n",
      "   macro avg       0.46      0.41      0.43      2340\n",
      "weighted avg       0.96      0.96      0.96      2340\n",
      "\n",
      "     Price  Shipping   Outlook   Quality  Size Shop_Service General Others\n",
      "0  Neutral  Negative  Positive      None  None         None    None   None\n",
      "1     None      None      None  Positive  None     Positive    None   None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/kaos/AfterGradEx/big_data/ABSA/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "train_df, test_df = load_and_merge(TRAIN_PATH, VAL_PATH, TEST_PATH)\n",
    "xgb_models, xgb_encoders, xgb_reports = train_xgb_models(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0afb8be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Predictions ===\n",
      "     Price  Shipping   Outlook Quality  Size Shop_Service General Others\n",
      "0  Neutral  Negative  Positive    None  None         None    None   None\n",
      "1     None  Negative  Negative    None  None         None    None   None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_texts = [\n",
    "    \"Gi√†y r·∫•t ƒë·∫πp, gi√° h·ª£p l√Ω nh∆∞ng giao h√†ng ch·∫≠m\",\n",
    "    \"Gi√° cao, gi√†y x·∫•u, shop giao h√†ng ch·∫≠m\"\n",
    "]\n",
    "\n",
    "print(\"=== XGBoost Predictions ===\")\n",
    "print(predict_aspects(xgb_models, xgb_encoders, sample_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdc359dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All existing models and encoders saved to disk\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save all models\n",
    "for aspect, model in xgb_models.items():\n",
    "    joblib.dump(model, os.path.join(MODEL_DIR, f\"{aspect}_xgb.pkl\"))\n",
    "\n",
    "# Save all encoders\n",
    "for aspect, encoder in xgb_encoders.items():\n",
    "    joblib.dump(encoder, os.path.join(MODEL_DIR, f\"{aspect}_encoder.pkl\"))\n",
    "\n",
    "print(\"‚úÖ All existing models and encoders saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a29beba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Pre-load models/encoders and broadcast them\n",
    "bc_models = {\n",
    "    aspect: spark.sparkContext.broadcast(joblib.load(os.path.join(MODEL_DIR, f\"{aspect}_xgb.pkl\")))\n",
    "    for aspect in ASPECTS\n",
    "}\n",
    "bc_encoders = {\n",
    "    aspect: spark.sparkContext.broadcast(joblib.load(os.path.join(MODEL_DIR, f\"{aspect}_encoder.pkl\")))\n",
    "    for aspect in ASPECTS\n",
    "}\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# UDF factory for each aspect\n",
    "# ----------------------\n",
    "def make_predict_udf(aspect):\n",
    "    model = bc_models[aspect].value\n",
    "    encoder = bc_encoders[aspect].value\n",
    "\n",
    "    @pandas_udf(StringType())\n",
    "    def predict_udf(texts: pd.Series) -> pd.Series:\n",
    "        texts_proc = [preprocess_xgb(t) for t in texts]\n",
    "        preds_encoded = model.predict(texts_proc)\n",
    "        preds_original = encoder.inverse_transform(preds_encoded)\n",
    "        return pd.Series([SENT_ID2NAME[int(x)] for x in preds_original])\n",
    "\n",
    "    return predict_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b7a6d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Price_pred</th>\n",
       "      <th>Shipping_pred</th>\n",
       "      <th>Outlook_pred</th>\n",
       "      <th>Quality_pred</th>\n",
       "      <th>Size_pred</th>\n",
       "      <th>Shop_Service_pred</th>\n",
       "      <th>General_pred</th>\n",
       "      <th>Others_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gi√†y h∆°i c√≥ m√πi n·ªìng, l∆∞u √Ω ƒë√¥i LA kh√¥ng ph·∫£i ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H√†ng v·ªÅ ƒë·∫πp l·∫Øm nha ship th√¢n thi·ªán ƒëi gi√†y v·ª´...</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H√†ng √¥k n√™n mua D√†y r·∫•t ƒë·∫πp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bun. GTI g·ª≠i Oke  s·ªõ ∆° ƒëi sidbd. B·ªüi ƒëi ƒë∆∞·ª£c ƒë...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M√†u ƒë·∫πp gi·ªëng trong h√¨nh m·ªçi ng∆∞·ªùi n√™n mua nha...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ch·∫•t l∆∞·ª£ng ph√π h·ª£p v·ªõi gi√° ti·ªÅn ƒëi ƒë√∫ng sz nh∆∞...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gi√†y tr∆∞·ª£t l·∫Øm huhu ƒê√°nh gi·∫£i tr∆∞·ªùng m√† tr∆∞·ª£t ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tr ∆°i d√©p ƒë·∫πp vs dth l·∫Øm nha vs gi√° n√†y m√† ch·∫•...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C≈©ng t·∫°m ƒë∆∞·ª£c thoi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shop h·ªó tr·ª£ r·∫•t t·ªët. Mn n√™n mua nh√©</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Price_pred Shipping_pred  \\\n",
       "0  Gi√†y h∆°i c√≥ m√πi n·ªìng, l∆∞u √Ω ƒë√¥i LA kh√¥ng ph·∫£i ...       None          None   \n",
       "1  H√†ng v·ªÅ ƒë·∫πp l·∫Øm nha ship th√¢n thi·ªán ƒëi gi√†y v·ª´...       None      Positive   \n",
       "2                        H√†ng √¥k n√™n mua D√†y r·∫•t ƒë·∫πp       None          None   \n",
       "3  Bun. GTI g·ª≠i Oke  s·ªõ ∆° ƒëi sidbd. B·ªüi ƒëi ƒë∆∞·ª£c ƒë...       None          None   \n",
       "4  M√†u ƒë·∫πp gi·ªëng trong h√¨nh m·ªçi ng∆∞·ªùi n√™n mua nha...       None          None   \n",
       "5  ch·∫•t l∆∞·ª£ng ph√π h·ª£p v·ªõi gi√° ti·ªÅn ƒëi ƒë√∫ng sz nh∆∞...       None          None   \n",
       "6  Gi√†y tr∆∞·ª£t l·∫Øm huhu ƒê√°nh gi·∫£i tr∆∞·ªùng m√† tr∆∞·ª£t ...       None          None   \n",
       "7  Tr ∆°i d√©p ƒë·∫πp vs dth l·∫Øm nha vs gi√° n√†y m√† ch·∫•...       None          None   \n",
       "8                                 C≈©ng t·∫°m ƒë∆∞·ª£c thoi       None          None   \n",
       "9                Shop h·ªó tr·ª£ r·∫•t t·ªët. Mn n√™n mua nh√©       None          None   \n",
       "\n",
       "  Outlook_pred Quality_pred Size_pred Shop_Service_pred General_pred  \\\n",
       "0         None         None      None              None     Positive   \n",
       "1     Positive         None  Positive              None         None   \n",
       "2     Positive         None      None              None         None   \n",
       "3         None         None      None              None         None   \n",
       "4     Positive         None      None              None         None   \n",
       "5         None      Neutral   Neutral              None         None   \n",
       "6     Positive         None      None              None         None   \n",
       "7     Positive     Positive  Positive              None         None   \n",
       "8         None         None      None              None      Neutral   \n",
       "9         None         None      None              None     Positive   \n",
       "\n",
       "  Others_pred  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "5        None  \n",
       "6        None  \n",
       "7        None  \n",
       "8        None  \n",
       "9        None  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some Spark dataframe (example: test data)\n",
    "spark_df = spark.read.csv(TEST_PATH, header=True)\n",
    "df = spark_df.limit(1000)\n",
    "\n",
    "# Add predictions for each aspect\n",
    "for aspect in ASPECTS:\n",
    "    predict_udf = make_predict_udf(aspect)\n",
    "    df = df.withColumn(f\"{aspect}_pred\", predict_udf(df[\"Review\"]))  # check column name\n",
    "\n",
    "# Show results\n",
    "cols_to_show = [\"Review\"] + [f\"{aspect}_pred\" for aspect in ASPECTS]\n",
    "df.select(*cols_to_show).limit(10).toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
